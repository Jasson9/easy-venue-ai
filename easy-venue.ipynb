{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting modal\n",
      "  Downloading modal-0.62.235-py3-none-any.whl (481 kB)\n",
      "     -------------------------------------- 481.0/481.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from modal) (2024.2.2)\n",
      "Collecting typer>=0.9\n",
      "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting grpclib==0.4.7\n",
      "  Downloading grpclib-0.4.7.tar.gz (61 kB)\n",
      "     ---------------------------------------- 61.3/61.3 kB 1.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0,>=3.19 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from modal) (4.25.3)\n",
      "Collecting watchfiles\n",
      "  Downloading watchfiles-0.22.0-cp310-none-win_amd64.whl (282 kB)\n",
      "     -------------------------------------- 282.1/282.1 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "     ---------------------------------------- 92.0/92.0 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting aiostream~=0.5.2\n",
      "  Downloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-win_amd64.whl (370 kB)\n",
      "     -------------------------------------- 370.7/370.7 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting synchronicity~=0.6.6\n",
      "  Downloading synchronicity-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting types-certifi\n",
      "  Downloading types_certifi-2021.10.8.3-py3-none-any.whl (2.1 kB)\n",
      "Collecting types-toml\n",
      "  Downloading types_toml-0.10.8.20240310-py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from modal) (13.7.1)\n",
      "Requirement already satisfied: click>=8.1.0 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from modal) (8.1.7)\n",
      "Collecting toml\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.6 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from modal) (4.9.0)\n",
      "Collecting h2<5,>=3.1.0\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting multidict\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: colorama in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from click>=8.1.0->modal) (0.4.6)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from rich>=12.0.0->modal) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from rich>=12.0.0->modal) (3.0.0)\n",
      "Collecting sigtools==4.0.1\n",
      "  Downloading sigtools-4.0.1-py2.py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting attrs\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.4/50.4 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting python-multipart>=0.0.7\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Collecting httpx>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.6/75.6 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting email_validator>=2.0.0\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from fastapi->modal) (1.10.14)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from fastapi->modal) (3.1.3)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1\n",
      "  Downloading ujson-5.10.0-cp310-cp310-win_amd64.whl (42 kB)\n",
      "     ---------------------------------------- 42.1/42.1 kB ? eta 0:00:00\n",
      "Collecting starlette<0.38.0,>=0.37.2\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.9/71.9 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting uvicorn[standard]>=0.12.0\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.4/62.4 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting orjson>=3.2.1\n",
      "  Downloading orjson-3.10.5-cp310-none-win_amd64.whl (141 kB)\n",
      "     -------------------------------------- 141.3/141.3 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting fastapi-cli>=0.0.2\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Collecting anyio>=3.0.0\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from anyio>=3.0.0->watchfiles->modal) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from anyio>=3.0.0->watchfiles->modal) (3.6)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "     -------------------------------------- 307.7/307.7 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting hyperframe<7,>=6.0\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.9/77.9 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from jinja2>=2.11.2->fastapi->modal) (2.1.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->modal) (0.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\codes\\nlp\\environments\\nlp\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->modal) (6.0.1)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp310-cp310-win_amd64.whl (58 kB)\n",
      "     ---------------------------------------- 58.2/58.2 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-12.0-cp310-cp310-win_amd64.whl (124 kB)\n",
      "     -------------------------------------- 125.0/125.0 kB 3.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: grpclib\n",
      "  Building wheel for grpclib (pyproject.toml): started\n",
      "  Building wheel for grpclib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76248 sha256=7ee8f149f148233d5d7c853f1194fa3b26654a97a70ee7e3b379e437e2410991\n",
      "  Stored in directory: c:\\users\\jasso\\appdata\\local\\pip\\cache\\wheels\\29\\ac\\91\\12059662699d04aa1307bd1d89f7c8cc26d127872187decba4\n",
      "Successfully built grpclib\n",
      "Installing collected packages: types-certifi, websockets, ujson, types-toml, toml, sniffio, shellingham, python-multipart, python-dotenv, orjson, multidict, hyperframe, httptools, hpack, h11, frozenlist, dnspython, attrs, async-timeout, aiostream, yarl, uvicorn, sigtools, httpcore, h2, email_validator, anyio, aiosignal, watchfiles, typer, synchronicity, starlette, httpx, grpclib, aiohttp, fastapi-cli, fastapi, modal\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.7.0\n",
      "    Uninstalling typer-0.7.0:\n",
      "      Successfully uninstalled typer-0.7.0\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 aiostream-0.5.2 anyio-4.4.0 async-timeout-4.0.3 attrs-23.2.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 frozenlist-1.4.1 grpclib-0.4.7 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 hyperframe-6.0.1 modal-0.62.235 multidict-6.0.5 orjson-3.10.5 python-dotenv-1.0.1 python-multipart-0.0.9 shellingham-1.5.4 sigtools-4.0.1 sniffio-1.3.1 starlette-0.37.2 synchronicity-0.6.7 toml-0.10.2 typer-0.12.3 types-certifi-2021.10.8.3 types-toml-0.10.8.20240310 ujson-5.10.0 uvicorn-0.30.1 watchfiles-0.22.0 websockets-12.0 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.5.3 requires typer<0.8.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â ‹ Waiting for authentication in the web browser\n",
      "â ™ Waiting for authentication in the web browser\n",
      "â ¹ Waiting for authentication in the web browser\n",
      "The web browser should have opened for you to authenticate and get an API \n",
      "token.\n",
      "If it didn't, please copy this URL into your web browser manually:\n",
      "\n",
      "â ¹ Waiting for authentication in the web browser\n",
      "https://modal.com/token-flow/tf-06EejetzsgQRCZrBjxuzaW\n",
      "\n",
      "â ¹ Waiting for authentication in the web browser\n",
      "â ¹ Waiting for authentication in the web browser\n",
      "\n",
      "â ‹ Waiting for token flow to complete...\n",
      "â ‹ Waiting for token flow to complete...\n",
      "â ™ Waiting for token flow to complete...\n",
      "â ¹ Waiting for token flow to complete...\n",
      "â ¼ Waiting for token flow to complete...\n",
      "â ´ Waiting for token flow to complete...\n",
      "â ¦ Waiting for token flow to complete...\n",
      "â § Waiting for token flow to complete...\n",
      "â ‡ Waiting for token flow to complete...\n",
      "â  Waiting for token flow to complete...\n",
      "â ‹ Waiting for token flow to complete...\n",
      "â ™ Waiting for token flow to complete...\n",
      "â ¹ Waiting for token flow to complete...\n",
      "â ¸ Waiting for token flow to complete...\n",
      "â ´ Waiting for token flow to complete...\n",
      "â ¦ Waiting for token flow to complete...\n",
      "â § Waiting for token flow to complete...\n",
      "â ‡ Waiting for token flow to complete...\n",
      "â  Waiting for token flow to complete...\n",
      "â ‹ Waiting for token flow to complete...\n",
      "â ™ Waiting for token flow to complete...\n",
      "â ¹ Waiting for token flow to complete...\n",
      "â ¸ Waiting for token flow to complete...\n",
      "â ¼ Waiting for token flow to complete...\n",
      "â ´ Waiting for token flow to complete...\n",
      "â ¦ Waiting for token flow to complete...\n",
      "â § Waiting for token flow to complete...\n",
      "â ‡ Waiting for token flow to complete...\n",
      "â  Waiting for token flow to complete...\n",
      "â ™ Waiting for token flow to complete...\n",
      "â ¹ Waiting for token flow to complete...\n",
      "â ¸ Waiting for token flow to complete...\n",
      "â ¼ Waiting for token flow to complete...\n",
      "â ´ Waiting for token flow to complete...\n",
      "â ¦ Waiting for token flow to complete...\n",
      "â § Waiting for token flow to complete...\n",
      "â ‡ Waiting for token flow to complete...\n",
      "â  Waiting for token flow to complete...\n",
      "â ‹ Waiting for token flow to complete...\n",
      "â ™ Waiting for token flow to complete...\n",
      "â ¹ Waiting for token flow to complete...\n",
      "â ¸ Waiting for token flow to complete...\n",
      "â ¼ Waiting for token flow to complete...\n",
      "â ´ Waiting for token flow to complete...\n",
      "â ¦ Waiting for token flow to complete...\n",
      "â § Waiting for token flow to complete...\n",
      "â ‡ Waiting for token flow to complete...\n",
      "â  Waiting for token flow to complete...\n",
      "â ‹ Waiting for token flow to complete...\n",
      "â ™ Waiting for token flow to complete...\n",
      "â ¹ Waiting for token flow to complete...\n",
      "â ¸ Waiting for token flow to complete...\n",
      "â ¼ Waiting for token flow to complete...\n",
      "\n",
      "Web authentication finished successfully!\n",
      "Token is connected to the jasson9 workspace.\n",
      "Verifying token against https://api.modal.com\n",
      "Token verified successfully!\n",
      "â ‹ Storing token\n",
      "\n",
      "Token written to C:\\Users\\jasso/.modal.toml in profile jasson9.\n"
     ]
    }
   ],
   "source": [
    "!modal setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created volume 'easy-venue' in environment 'None'. \n",
      "\n",
      "Code example:\n",
      "\n",
      "                                                                               \n",
      "@app.function(volumes={\"/my_vol\": modal.Volume.from_name(\"easy-venue\")})       \n",
      "def some_func():                                                               \n",
      "    os.listdir(\"/my_vol\")                                                      \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "!modal volume create easy-venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "\\ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "\\ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "\\ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "\\ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "\\ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "\\ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "/ Uploading file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'...\n",
      "âœ“ Uploaded file 'Bangalore_venues.csv' to 'Bangalore_venues.csv'\n"
     ]
    }
   ],
   "source": [
    "!modal volume put easy-venue Bangalore_venues.csv Bangalore_venues.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "\n",
    "vol = modal.Volume.from_name(\"easy-venue\")\n",
    "image = (\n",
    "    modal.Image.debian_slim(python_version=\"3.10\")\n",
    "    .pip_install(\"pandas\", \"numpy\", \"scikit-learn\")\n",
    ")\n",
    "app = modal.App(name=\"easy-venue-recommendation-system\",volumes={\"/easy-venue\": vol},image=image)\n",
    "\n",
    "def get_recommendations(name, top_n=10):\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import numpy as np\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    data = pd.read_csv('/easy-venue/Bangalore_venues.csv')\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf.fit(data['categories'])\n",
    "    text_vec = tfidf.transform([name])\n",
    "    cosine_sim = cosine_similarity(text_vec, tfidf.transform(data['categories']))\n",
    "    idxs = np.argsort(cosine_sim[0])[-top_n:][::-1]\n",
    "    return data.iloc[idxs]['id']\n",
    "\n",
    "@app.function(image=image, volumes={\"/easy-venue\": vol})\n",
    "@modal.web_endpoint(method=\"POST\")\n",
    "def recommend(category: str)->str:\n",
    "    ids = get_recommendations(category)\n",
    "    return ids.to_json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Creating objects...\n",
      "\\ Creating objects...\n",
      "/ Creating objects...\n",
      "\\ Creating objects...\n",
      "â””â”€â”€ - Creating mount g:\\Codes\\NLP\\easy-venue.py: Uploaded 0/1 files\n",
      "/ Creating objects...\n",
      "â””â”€â”€ \\ Creating mount g:\\Codes\\NLP\\easy-venue.py: Uploaded 0/1 files\n",
      "\\ Creating objects...\n",
      "â””â”€â”€ / Creating mount g:\\Codes\\NLP\\easy-venue.py: Uploaded 0/1 files\n",
      "/ Creating objects...\n",
      "â””â”€â”€ \\ Creating mount g:\\Codes\\NLP\\easy-venue.py: Uploaded 0/1 files\n",
      "\\ Creating objects...\n",
      "â””â”€â”€ / Creating mount g:\\Codes\\NLP\\easy-venue.py: Uploaded 0/1 files\n",
      "/ Creating objects...\n",
      "â””â”€â”€ \\ Creating mount g:\\Codes\\NLP\\easy-venue.py: Finalizing index of 1 files\n",
      "\\ Creating objects...\n",
      "â””â”€â”€ / Creating mount g:\\Codes\\NLP\\easy-venue.py: Finalizing index of 1 files\n",
      "/ Creating objects...\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ - Creating function WebApp.recommend...\n",
      "\\ Creating objects...\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ \\ Creating function WebApp.recommend...\n",
      "/ Creating objects...\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ / Creating function WebApp.recommend...\n",
      "\\ Creating objects...\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ ðŸ”¨ Created web function WebApp.recommend => \n",
      "    https://jasson9--easy-venue-recommendation-system-webapp-recommend.modal.ru\n",
      "    n\n",
      "/ Creating objects...\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ ðŸ”¨ Created web function WebApp.recommend => \n",
      "    https://jasson9--easy-venue-recommendation-system-webapp-recommend.modal.ru\n",
      "    n\n",
      "- Creating objects...\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ ðŸ”¨ Created web function WebApp.recommend => \n",
      "    https://jasson9--easy-venue-recommendation-system-webapp-recommend.modal.ru\n",
      "    n\n",
      "\n",
      "âœ“ Created objects.\n",
      "â”œâ”€â”€ ðŸ”¨ Created mount g:\\Codes\\NLP\\easy-venue.py\n",
      "â””â”€â”€ ðŸ”¨ Created web function WebApp.recommend => \n",
      "    https://jasson9--easy-venue-recommendation-system-webapp-recommend.modal.ru\n",
      "    n\n",
      "âœ“ App deployed! ðŸŽ‰\n",
      "\n",
      "View Deployment: \n",
      "https://modal.com/jasson9/main/apps/deployed/easy-venue-recommendation-system\n"
     ]
    }
   ],
   "source": [
    "!modal deploy easy-venue.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bangalore_venues_custom.json'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "venues_df = pd.read_csv('Bangalore_venues.csv')\n",
    "\n",
    "# Function to generate random dummy data with specific constraints for price and rating\n",
    "def generate_custom_dummy_data(row):\n",
    "    states = [\"Karnataka\", \"Maharashtra\", \"Tamil Nadu\", \"Delhi\", \"West Bengal\"]\n",
    "    countries = [\"India\", \"USA\", \"UK\", \"Australia\", \"Canada\"]\n",
    "    amenities_list = [\n",
    "        [\"Parking\", \"Wi-Fi\", \"Restrooms\"],\n",
    "        [\"Valet Parking\", \"Gym\", \"Spa\"],\n",
    "        [\"Swimming Pool\", \"Bar\", \"Restaurant\"],\n",
    "        [\"Wi-Fi\", \"Conference Rooms\", \"Business Center\"],\n",
    "        [\"Play Area\", \"Arcade\", \"Food Court\"]\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"venueId\": row[\"id\"],\n",
    "        \"name\": row[\"name\"],\n",
    "        \"address\": str(row[\"address\"]),\n",
    "        \"state\": random.choice(states),\n",
    "        \"country\": random.choice(countries),\n",
    "        \"zip\": f\"{random.randint(100000, 999999)}\",\n",
    "        \"phone\": f\"+91 {random.randint(10000, 99999)} {random.randint(10000, 99999)}\",\n",
    "        \"email\": f\"contact{random.randint(1, 100)}@example.com\",\n",
    "        \"website\": f\"https://example.com/{row['id']}\",\n",
    "        \"category\": row[\"categories\"],\n",
    "        \"price\": random.randint(100000, 500000),\n",
    "        \"description\": f\"{row['name']} is a popular place for {row['categories'].lower()}.\",\n",
    "        \"capacity\": random.randint(50, 5000),\n",
    "        \"rating\": np.round(random.uniform(3.0, 5.0),1) ,\n",
    "        \"latitude\": row[\"lat\"],\n",
    "        \"longitude\": row[\"lng\"],\n",
    "        \"amenities\": random.choice(amenities_list),\n",
    "        \"createdAt\": datetime.now().isoformat(),\n",
    "        \"updatedAt\": datetime.now().isoformat(),\n",
    "        \"image\": f\"https://example.com/images/{row['id']}.jpg\"\n",
    "    }\n",
    "\n",
    "# Transform the DataFrame to JSON format with custom constraints for price and rating\n",
    "custom_venues_json = [generate_custom_dummy_data(row) for index, row in venues_df.iterrows()]\n",
    "\n",
    "# Save the custom JSON data to a file\n",
    "custom_output_path = 'Bangalore_venues_custom.json'\n",
    "with open(custom_output_path, 'w') as json_file:\n",
    "    json.dump(custom_venues_json, json_file, indent=2)\n",
    "\n",
    "custom_output_path\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
